import streamlit as st
import requests

BASE_URL = "http://localhost:8000"
st.set_page_config(layout="wide", page_title="POC for Notesight")

st.sidebar.title("Features")
page = st.sidebar.radio("Go to", ["Notes", "Flashcards", "Chat", "MCQ"])

# ---- Initialize session state ----
if "notes_text" not in st.session_state:
    st.session_state.notes_text = ""

if "flashcards" not in st.session_state:
    st.session_state.flashcards = []

if "topics_hierarchy" not in st.session_state:
    st.session_state["topics_hierarchy"] = {}
if "selected_topics" not in st.session_state:
    st.session_state["selected_topics"] = []


if "messages" not in st.session_state:
    st.session_state.messages = []

# ---- Notes Page ----
if page == "Notes":
    st.title("Notesight POC - üìÑ Generate Notes")

    uploaded_files = st.file_uploader("Upload PDFs for Notes Generation", accept_multiple_files=True)
    model_options = {"Gemini": "gemini", "ChatGPT": "chatgpt", "Mistral": "mistral"}
    model = st.selectbox("Select AI Model", list(model_options.values()))

    if uploaded_files and st.button("üìù Generate Notes"):
        files = [("files", (file.name, file, "application/pdf")) for file in uploaded_files]
        response = requests.post(f"{BASE_URL}/notes/", files=files, data={"model": model}, stream=True)

        if response.status_code == 200:
            st.session_state.notes_text = ""  # Clear old notes
            notes_placeholder = st.empty()

            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    st.session_state.notes_text += chunk.decode("utf-8")
                    notes_placeholder.markdown(st.session_state.notes_text)

        else:
            st.error("‚ùå Failed to generate notes")

    if st.session_state.notes_text:
        st.subheader("Generated Notes:")
        st.markdown(st.session_state.notes_text)

# ---- Flashcards Page ----
elif page == "Flashcards":
    st.title("Notesight POC - üìö Flashcard Generator")
    uploaded_files = st.file_uploader("Upload PDFs for Flashcards", type=["pdf", "txt", "png", "jpg", "jpeg"], accept_multiple_files=True)
    model_options = {"Gemini": "gemini", "ChatGPT": "chatgpt", "Mistral": "mistral"}
    selected_model = st.selectbox("Select AI Model", list(model_options.keys()))

    if uploaded_files and st.button("üîπ Generate Flashcards"):
        files = [("files", (file.name, file, "application/pdf")) for file in uploaded_files]
        data = {"model": model_options[selected_model]}

        with st.spinner(f"Generating flashcards using {selected_model}... ‚è≥"):
            response = requests.post(f"{BASE_URL}/flashcards/", files=files, data=data)

            if response.status_code == 200:
                st.session_state.flashcards = response.json().get("flashcards", [])

                if st.session_state.flashcards:
                    st.success(f"‚úÖ Flashcards Generated Using {selected_model}")
                else:
                    st.warning("‚ö† No flashcards were generated.")
            else:
                st.error(f"‚ùå Failed to generate flashcards using {selected_model}")

    if st.session_state.flashcards:
        st.subheader(f"üìù Flashcards (Generated by {selected_model})")
        for flashcard in st.session_state.flashcards:
            with st.expander(f"**{flashcard.get('concept', 'Unknown Concept')}**"):
                st.write(flashcard.get("definition", "No Definition Provided"))

# ---- Chat Page ----
elif page == "Chat":
    st.title("Notesight POC - Document QA")

    uploaded_file = st.file_uploader("Upload a PDF document", type=["pdf"])

    if uploaded_file and st.button("üì§ Upload File"):
        files = {"file": (uploaded_file.name, uploaded_file, "application/pdf")}
        response = requests.post(f"{BASE_URL}/upload/", files=files)

        if response.status_code == 200:
            st.success("‚úÖ File uploaded successfully!")
            st.session_state.file_path = response.json().get("file_path")
        else:
            st.error("‚ùå Failed to upload file")
            st.stop()

    st.subheader("üí¨ Ask Questions About the Document")

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    query = st.chat_input("Ask a question about the document...")
    if query:
        with st.chat_message("user"):
            st.markdown(query)
        st.session_state.messages.append({"role": "user", "content": query})

        response = requests.post(f"{BASE_URL}/ask/", data={"query": query})

        answer = response.json().get("answer", "‚ö† No response received.") if response.status_code == 200 else "‚ùå Error: Failed to get a response."

        with st.chat_message("assistant"):
            st.markdown(answer)

        st.session_state.messages.append({"role": "assistant", "content": answer})

elif page == "MCQ":
    st.title("üìò Notesight POC - Generate MCQs")

    uploaded_files = st.file_uploader("üìÇ Upload PDFs for MCQ generation", type=["pdf"], accept_multiple_files=True)
    MODEL_OPTIONS = {"Gemini": "gemini", "ChatGPT": "chatgpt", "Mistral": "mistral"}
    selected_model = st.selectbox("ü§ñ Select AI Model", list(MODEL_OPTIONS.keys()))
    selected_model_key = MODEL_OPTIONS[selected_model]

    if uploaded_files and st.button("üîç Extract Topics"):
        files = [("files", (file.name, file, "application/pdf")) for file in uploaded_files]
        with st.spinner(f"Extracting topics {selected_model.capitalize()}... ‚è≥"):
            response = requests.post(f"{BASE_URL}/mcqs/", files=files, data={"model": selected_model_key})

            if response.status_code == 200:
                st.session_state["topics_hierarchy"] = response.json().get("topics", {})
                st.success("‚úÖ Topics Extracted! Select subtopics below.")
                st.session_state["file_paths"] = response.json().get("file_paths", [])
            else:
                st.error("‚ùå Failed to extract topics.")

    if "topics_hierarchy" in st.session_state and st.session_state["topics_hierarchy"]:
        st.subheader("üìë Select Subtopics for MCQ Generation")
        selected_subtopics = []

        for chapter, subtopics in st.session_state["topics_hierarchy"].items():
            with st.expander(f"üìñ {chapter}"):
                chapter_selected = st.checkbox(f"Select All in {chapter}", key=f"{chapter}_all")
                for subtopic in subtopics:
                    subtopic_selected = st.checkbox(subtopic, key=f"{chapter}_{subtopic}", value=chapter_selected)
                    if subtopic_selected:
                        selected_subtopics.append(subtopic)

        st.session_state["selected_subtopics"] = selected_subtopics

    if "selected_subtopics" in st.session_state and st.session_state["selected_subtopics"] and st.button("üéØ Generate MCQs"):
        # Save uploaded files and get file paths
        with st.spinner(f"Generating MCQs using {selected_model.capitalize()}... ‚è≥"):
            response = requests.post(
                f"{BASE_URL}/mcqs/generate/",
                json={"topics": st.session_state["selected_subtopics"], "file_paths": st.session_state["file_paths"], "model": selected_model}
            )

        if response.status_code == 200:
            mcqs = response.json()
            if mcqs:
                st.subheader("üìö Generated MCQs")
                for mcq in mcqs:
                    with st.expander(f"üìù {mcq['question']}"):
                        for option in mcq["options"]:
                            st.write(f"{option}")
                        st.success(f"‚úÖ Correct Answer: {mcq['correct_answer']}")
            else:
                st.warning("‚ö† No MCQs were generated.")
        else:
            st.error("‚ùå Failed to generate MCQs. Please try again.")
